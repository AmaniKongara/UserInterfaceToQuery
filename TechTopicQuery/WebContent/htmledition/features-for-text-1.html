
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>

<!-- Mirrored from nlp.stanford.edu/IR-book/html/htmledition/features-for-text-1.html by HTTrack Website Copier/3.x [XR&CO'2013], Sat, 08 Feb 2014 19:34:19 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<HEAD>
<TITLE>Features for text</TITLE>
<META NAME="description" CONTENT="Features for text">
<META NAME="keywords" CONTENT="irbook">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="irbook-2.html">

<LINK REL="next" HREF="document-zones-in-text-classification-1.html">
<LINK REL="previous" HREF="large-and-difficult-category-taxonomies-1.html">
<LINK REL="up" HREF="improving-classifier-performance-1.html">
<LINK REL="next" HREF="document-zones-in-text-classification-1.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html4001"
  HREF="document-zones-in-text-classification-1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="../icons/next.png"></A> 
<A NAME="tex2html3995"
  HREF="improving-classifier-performance-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="../icons/up.png"></A> 
<A NAME="tex2html3989"
  HREF="large-and-difficult-category-taxonomies-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="../icons/prev.png"></A> 
<A NAME="tex2html3997"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="../icons/contents.png"></A> 
<A NAME="tex2html3999"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="../icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html4002"
  HREF="document-zones-in-text-classification-1.html">Document zones in text</A>
<B> Up:</B> <A NAME="tex2html3996"
  HREF="improving-classifier-performance-1.html">Improving classifier performance</A>
<B> Previous:</B> <A NAME="tex2html3990"
  HREF="large-and-difficult-category-taxonomies-1.html">Large and difficult category</A>
 &nbsp; <B>  <A NAME="tex2html3998"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html4000"
  HREF="index-1.html">Index</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->

<H3><A NAME="SECTION002032200000000000000">
Features for text</A>
</H3>

<P>
The default in both ad hoc retrieval and text classification is to use
terms as features.  However, for text classification, a great deal of
mileage can be achieved by designing additional features which are
suited to a specific problem.  Unlike the case of IR query languages,
since these features are internal to the 
classifier, there is no problem of communicating these features to an
end user.  This process is generally referred to as <A NAME="22955"></A> <I>feature
engineering</I> .  At present, feature engineering remains a human craft,
rather than something done by machine learning.  Good feature
engineering can often markedly improve the performance of a text
classifier.  It is especially beneficial in some of the most important
applications of text classification, like 
<A NAME="22957"></A> <I>spam</I> 
and <A NAME="22959"></A> <I>porn</I>  filtering.

<P>
Classification problems will often contain large numbers of terms
which can be conveniently grouped, and which have a similar vote in
text classification problems.  Typical examples might be year mentions
or strings of exclamation marks.  Or they may be more specialized
tokens like ISBNs or chemical formulas.
Often, using them directly in a classifier would greatly increase
the vocabulary without providing classificatory power beyond
knowing that, say, a chemical formula is present.
In such cases,
the number of features and feature sparseness can be reduced by
matching such items with regular expressions and converting them into
distinguished tokens.  Consequently, effectiveness and classifier
speed are normally enhanced.
Sometimes all numbers are converted into a single feature, 
but often some value can be had by distinguishing
different kinds of numbers, such as four digit numbers (which are
usually years) versus other cardinal numbers versus real numbers with
a decimal point.  Similar techniques can be applied to dates, ISBN
numbers, sports game scores, and so on.

<P>
Going in the other direction, it is often useful to
increase the number of features by matching parts of words, and by
matching selected multiword patterns that are particularly
discriminative.  Parts of words are often matched by character
<IMG
 WIDTH="11" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.png"
 ALT="$k$">-gram features.  Such features can be particularly good at providing
classification clues for otherwise unknown words when the classifier
is deployed.  For instance, an unknown word ending in <I>-rase</I> is
likely to be an enzyme, even if it wasn't seen in the training data.
Good multiword patterns are often found by looking for distinctively
common word pairs (perhaps using a mutual information criterion
between words, in a similar way to its use in Section&nbsp;<A HREF="mutual-information-1.html#sec:mutualinfo">13.5.1</A> (page&nbsp;<A HREF="mutual-information-1.html#p:mutualinfo"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="../icons/crossref.png"></A>)
for feature selection) and then using feature selection methods evaluated
against classes.  They are useful when the components of a compound
would themselves be misleading as classification cues.  For instance,
this would be the case if the keyword <I>ethnic</I> was most
indicative of the categories <I>food</I> and <I>arts</I>, the
keyword <I>cleansing</I> was most indicative of the category
<I>home</I>, but the collocation <I>ethnic cleansing</I> instead
indicates the category <I>world news</I>.  Some text classifiers also
make use of features from <A NAME="22971"></A>named entity recognizers (cf. page <A HREF="xml-retrieval-1.html#p:ner-ref">10</A> ). 

<P>
Do techniques like stemming and lowercasing (vocabulary) help
for text classification?  As always, the ultimate test is empirical
evaluations conducted on an appropriate test collection.  But it is
nevertheless useful to note that such techniques have a more
restricted chance of being useful for classification.  For IR, you
often need to collapse forms of a word like <I>oxygenate</I> and
<I>oxygenation</I>, because the appearance of either in a document is
a good clue that the document will be relevant to a query about
oxygenation.  Given copious training
data, stemming necessarily delivers no value for text classification.
If several forms that stem together have a similar
signal, the parameters estimated for all of them will have similar
weights.  Techniques like stemming help only in compensating for data
sparseness.  This can be a useful role (as noted at the start of this
section), but often different forms of a word can convey significantly
different cues about the correct document classification.  Overly
aggressive stemming can easily degrade classification performance.

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html4001"
  HREF="document-zones-in-text-classification-1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="../icons/next.png"></A> 
<A NAME="tex2html3995"
  HREF="improving-classifier-performance-1.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="../icons/up.png"></A> 
<A NAME="tex2html3989"
  HREF="large-and-difficult-category-taxonomies-1.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="../icons/prev.png"></A> 
<A NAME="tex2html3997"
  HREF="contents-1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="../icons/contents.png"></A> 
<A NAME="tex2html3999"
  HREF="index-1.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index"
 SRC="../icons/index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html4002"
  HREF="document-zones-in-text-classification-1.html">Document zones in text</A>
<B> Up:</B> <A NAME="tex2html3996"
  HREF="improving-classifier-performance-1.html">Improving classifier performance</A>
<B> Previous:</B> <A NAME="tex2html3990"
  HREF="large-and-difficult-category-taxonomies-1.html">Large and difficult category</A>
 &nbsp; <B>  <A NAME="tex2html3998"
  HREF="contents-1.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html4000"
  HREF="index-1.html">Index</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
&copy; 2008 Cambridge University Press<br>This is an automatically generated page. In case of formatting errors you may want to look at the <a href=http://informationretrieval.org/>PDF edition</a> of the book.<br>
2009-04-07
</ADDRESS>
</BODY>

<!-- Mirrored from nlp.stanford.edu/IR-book/html/htmledition/features-for-text-1.html by HTTrack Website Copier/3.x [XR&CO'2013], Sat, 08 Feb 2014 19:34:19 GMT -->
</HTML>
